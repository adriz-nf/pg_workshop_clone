{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd08d18",
   "metadata": {},
   "source": [
    "In case you have a Google account, open the file with [Google Colab](https://colab.research.google.com), which \"...  allows anybody to write and execute arbitrary python code.\" [(Source)](https://research.google.com/colaboratory/faq.html)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neuefische/pg_workshop/blob/main/4_youtube_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49cd26",
   "metadata": {},
   "source": [
    "# Performing structured Data Analysis with Python using Jupyter Notebooks - Part 2\n",
    "## Exploring Daily Statistics for Trending YouTube Videos\n",
    "\n",
    "In the last notebook, you have seen an example for performing a Data Analysis with Python using a Jupyter Notebook and its usefulness for sharing code and insights.\n",
    "\n",
    "The following notebook is just a further but much more extensive example for a structured Data Analysis including Story-telling with Python. This time, also the cleaning part in included in the Analytics Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/e/e1/Logo_of_YouTube_%282015-2017%29.svg\", width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eaf11e",
   "metadata": {},
   "source": [
    "**OBJECTIVE OF THIS NOTEBOOK**  \n",
    "This notebook contains a further example for performing Data Analysis with Python using a Jupyter Notebook. This time, you will look at daily statistics for trending YouTube videos.\n",
    "You will go through the cleaning and feature engineering part of the Analytics workflow as well as the hypotheses making and testing part.\n",
    "After going through this code-along you will have a better idea about\n",
    "- using Jupyter Notebooks for sharing code and insights\n",
    "- performing a data analysis using Python in Jupyter Notebooks\n",
    "- what lines of code are commonly used within a Data Analysis\n",
    "- how to build and test hypotheses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d3e9f",
   "metadata": {},
   "source": [
    "**CONTENT OF THIS NOTEBOOK**  \n",
    "In this notebook we will have a look at daily statistics for trending YouTube videos.  \n",
    "\n",
    "The data as well as the data-descriptions are retrieved from [Kaggle](https://www.kaggle.com/datasnaek/youtube-new). The data was collected from Google's You Tube API using an open-source tool available on [Github](https://github.com/mitchelljy/Trending-YouTube-Scraper).  \n",
    "There you can find the following description of this data:  \n",
    "\"YouTube (the world-famous video sharing website) maintains a list of the top trending videos on the platform. According to Variety magazine, “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangnam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.\"  \n",
    "\n",
    "*What does trending mean?*  \n",
    "According to [YouTube](https://support.google.com/youtube/answer/7239739?hl=en), trending helps viewers see what’s happening on YouTube and in the world. Trending aims to surface videos that a wide range of viewers would find interesting. Some trends are predictable, like a new song from a popular artist or a new movie trailer. Others are surprising, like a viral video. Trending isn’t personalized and displays the same list of trending videos in each country to all users.  \n",
    "The list of trending videos is updated roughly every 15 minutes. With each update, videos may move up, down, or stay in the same position in the list.\n",
    "\n",
    "Data are available for different countries as separate files, in this notebook we will use the daily statistics for Germany for the years 2017/2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bebeb",
   "metadata": {},
   "source": [
    "**BUSINESS CASE**  \n",
    "You work as Data Analyst for a music agency, which has a lot of prospective music stars under contract.  \n",
    "The agency instructed you to give them an overview about how likely it is, that videos of their stars become trending videos on YouTube, how long it will take and if there are influenceable factors, which determine whether the videos become trending or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8eb8e0",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "Carefully read through the documentation, lines of code and execute the code blocks below.  \n",
    "There are tasks for you to solve in between: Sometimes you need to write your own code, sometimes you should write down some insights/ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3100f1",
   "metadata": {},
   "source": [
    "# 1 Ask questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d761fb",
   "metadata": {},
   "source": [
    "Based on the task the agency gave you, you have outlined the following questions for your analysis:\n",
    "    \n",
    "- Do music videos often become trending videos? Are other categories more successful? \n",
    "- How long does it take on average for music videos to become trending videos?\n",
    "- Which channels might be a good choice to publish videos? \n",
    "- When is a good time to publish a video?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46afac",
   "metadata": {},
   "source": [
    "# 2 Load your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ae793",
   "metadata": {},
   "source": [
    "Set-up your working environment and load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1811acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries you need for your analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01979d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floats (decimal numbers) should be displayed rounded with 2 decimal places\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "# Set style for plots\n",
    "plt.style.use('fivethirtyeight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cc4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file \n",
    "url = \"https://raw.githubusercontent.com/neuefische/pg_workshop/main/data/DEvideos.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed5758",
   "metadata": {},
   "source": [
    "# 3 Understand your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618b463",
   "metadata": {},
   "source": [
    "As first part of an analysis it is important to find out what information is contained in the dataset.  \n",
    "We start by looking at some basic information in our dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first 5 rows of datset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which columns are included in our dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e8c60",
   "metadata": {},
   "source": [
    "In order to really understand the data, we need to know what information the different columns contain.    \n",
    "Here are the explanations of the individual variables:\n",
    "\n",
    "\n",
    "| Column name | Description |\n",
    "| --- | ----------- |\n",
    "| video_id | Unique identifier for each uploaded video|\n",
    "| trending_date | Date on which this video was trending|\n",
    "| title | Video title|\n",
    "| channel_title | Name of YouTube channel |\n",
    "| category_id  | Category video belongs to |\n",
    "| publish_time| Date and time, video was published |\n",
    "| tags| Tags used for this video|\n",
    "| views | Number of views |\n",
    "| likes | Number of likes |\n",
    "| dislikes | Number of dislikes |\n",
    "| comment_count | Number of comments |\n",
    "| thumbnail link | Link to reduced-size versions of pictures or videos |\n",
    "| comments_disabled | States, if comments were disabled or not |\n",
    "| ratings_disabled | States, if ratings were disabled or not |\n",
    "| video_error_or_removed | States, if there was an error or if video was removed |\n",
    "| description | Description of video content |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the shape of our dataset, meaning how long and wide it is.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ef384",
   "metadata": {},
   "source": [
    "We have 40840 rows and 16 columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d19aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want to check out our data-types as well as get a feeling for possible missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a079fe",
   "metadata": {},
   "source": [
    "**Data-types**  \n",
    "- object: We see that we have a lot of object data-types in our dataset. This means, we have strings (meaning text) or mixed data-types in these columns. For video_id, title, channel_title, tags, thumbnail_link and description this is true - however talking about trending_date and publish_date we need to change our data-types into a date format. We will keep that in mind and come back to this later.  \n",
    "- int64: Furthermore we have integers in category_id, views, likes, dislikes and comment_count, which makes sense, since we are expecting numerical values there.  \n",
    "- bool: The boolean type indicates, that values are either True or False in these three columns - which makes sense when looking at our column names and descriptions.   \n",
    " **Missing values**  \n",
    " Below the header *Non-Null* we see how many non-null (not missing) values we have per column.  Except for description, we have 40840 non-null values in each column which is exactly the same number as we have rows.   \n",
    " Meaning: We only seem to have missing values in the description column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6eea3f",
   "metadata": {},
   "source": [
    "### Task\n",
    "Try out the following method on your dataframe and see, what output you get:  \n",
    "[.tail()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313f92b",
   "metadata": {},
   "source": [
    "# 4 Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4eb76b",
   "metadata": {
    "tags": []
   },
   "source": [
    "After browsing through our data and figuring out, what data we have in front of us, we now need to prepare our data for further analysis.  \n",
    "Generally we assume the data is complete (has no missing values) and is correct (has no obvious logical problems that defy our understanding of the content).  \n",
    "We can test these assumptions and confirm our data is valid before moving on with our analysis.  \n",
    "\n",
    "You will realize, that there is some work to do before starting with our actual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62fcc0",
   "metadata": {},
   "source": [
    "## Explore and clean your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed564c2",
   "metadata": {},
   "source": [
    "In order to test our hypotheses, we will now explore our data in more detail.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2261b0",
   "metadata": {},
   "source": [
    "**Drop columns**  \n",
    "Since we are not interested in all the columns, we can drop some of these to make our exploration easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f252a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't need\n",
    "df.drop([\"tags\",\"thumbnail_link\", \"comments_disabled\", \"ratings_disabled\", \"video_error_or_removed\", \"description\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result with .head() and .info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefcefd",
   "metadata": {},
   "source": [
    "**Deal with duplicate rows**  \n",
    "Let's check if we have the same videos (with the same video_id) several times in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate rows in video_id column\n",
    "df[\"video_id\"].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c38aa",
   "metadata": {},
   "source": [
    "We have data on 40840 trending videos to analyze. On YouTube, the same video might appear on the trending list for many days. This means that the 40840 videos are not unique videos. In fact, among the 40840 videos, we have 29627 unique videos.  \n",
    "These duplicate rows exist, since some of the videos stayed on the trending list for more than one day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1b714",
   "metadata": {},
   "source": [
    "As stated in [this analysis](https://ammar-alyousfi.com/2020/youtube-trending-videos-analysis-2019-us), we will apply the following analysis on all of our 40840 trending videos and not only on the unique trending videos. This will give videos which were trending for several days more weight, which is in our interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6a476",
   "metadata": {},
   "source": [
    "**Transform data types**  \n",
    "As stated above, we need to transform trending_date and publish_time into a datetime format.  \n",
    "Fortunately, there is a built-in function in pandas, which will convert an argument to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22726509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert trending_date and publish_time into datetime and extract date part from publish_time\n",
    "# format specifies the present form of our argument we pass into the function\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df['publish_date'] = pd.to_datetime(df['publish_time'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8f9ba",
   "metadata": {},
   "source": [
    "**Build new columns/ Feature engineering**  \n",
    "Since we want to know, when a good timing for publishing a video is, we should look at the time when most trending videos get published. Thus, we need to create new columns which contain information about the day of the week as well as the time of the day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year, month, dayofweek and hour information out of column publish_time and build new column for each\n",
    "df[\"publish_year\"]=df[\"publish_time\"].dt.year\n",
    "df[\"publish_month\"]=df[\"publish_time\"].dt.month\n",
    "df[\"publish_weekday\"]=df[\"publish_time\"].dt.dayofweek\n",
    "df[\"publish_hour\"]=df[\"publish_time\"].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b608c4a",
   "metadata": {},
   "source": [
    "*Note*:\n",
    "Day of week: Return the day of the week. It is assumed the week starts on Monday, which is denoted by 0 and ends on Sunday which is denoted by 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ab8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cb08c",
   "metadata": {},
   "source": [
    "Let's also do this for the trending date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de60cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year, month, day-of-week out of column trending_date and build new column for each\n",
    "df[\"trending_year\"]=df[\"trending_date\"].dt.year\n",
    "df[\"trending_month\"]=df[\"trending_date\"].dt.month\n",
    "df[\"trending_weekday\"]=df[\"trending_date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e334c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d5b9a",
   "metadata": {},
   "source": [
    "We want to know, if videos of the category *Music* often become trending videos. Thus, we need to compare the different categories of videos - however so far, we only have an category ID and don't know what's behind this ID.  \n",
    "Fortunately we can decode the IDs and transform them into actual category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary called category_names with category_id as key and the actual category name as value\n",
    "# we get these values from the Google API or here: https://gist.github.com/dgp/1b24bf2961521bd75d6c\n",
    "category_names = {\n",
    "    1:'Film and Animation',\n",
    "    2:'Autos & Vehicles',\n",
    "    10:'Music',\n",
    "    15:'Pets and Animals',\n",
    "    17:'Sports',\n",
    "    18:'Short Movies',\n",
    "    19:'Travel and Events',\n",
    "    20:'Gaming',\n",
    "    21:'Videoblogging',\n",
    "    22:'People and Blogs',\n",
    "    23:'Comedy',\n",
    "    24:'Entertainment',\n",
    "    25:'News and Politics',\n",
    "    26:'How to and Style',\n",
    "    27:'Education',\n",
    "    28:'Science and Technology',\n",
    "    29:'Non Profits and Activism',\n",
    "    30:'Movies',\n",
    "    31:'Anime/Animation', \n",
    "    32:'Action/Adventure',\n",
    "    33:'Classics',\n",
    "    34:'Comedy', \n",
    "    35:'Documentary',\n",
    "    36:'Drama',\n",
    "    37:'Family',\n",
    "    38:'Foreign',\n",
    "    39:'Horror',\n",
    "    40:'Sci-Fi/Fantasy',\n",
    "    41:'Thriller',\n",
    "    42:'Shorts',\n",
    "    43:'Shows',\n",
    "    44:'Trailers'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column called category_name which contains the name of the category, the video belongs to\n",
    "# the map() function is used to map values of Series according to input correspondence (https://www.w3resource.com/pandas/series/series-map.php)\n",
    "df['category_name'] = df['category_id'].map(category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebc734",
   "metadata": {},
   "source": [
    "### Task\n",
    "Check if the mapping worked by showing the head of your dataframe only for the three columns \"title\", \"category_id\" and \"category_name\". You need to select several columns by specifying their names: https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c15dc0",
   "metadata": {},
   "source": [
    "#### Days between publishing and trending\n",
    "We want to know, how long it takes on average for music videos to become trending videos. Thus, we need to have a look at the time-interval between video-publication-date and the trending_date.  \n",
    "Therefore we need to create a new column including the time interval in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column called trending_days_difference\n",
    "df['trending_days_difference']=(df[\"trending_date\"]-df[\"publish_date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46085c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result\n",
    "df[[\"trending_date\", \"publish_date\", \"trending_days_difference\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae623da",
   "metadata": {},
   "source": [
    "**Missing values**  \n",
    "We have already seen above, that we only have missing values in the description column, which we have dropped.  \n",
    "Let's confirm this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays sum of missing values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60623ee",
   "metadata": {},
   "source": [
    "There are no other missing values we have to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c06f8",
   "metadata": {},
   "source": [
    "**Descriptive Statistics**  \n",
    "Let's have a look at our numerical variables and their descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b82f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the describe() function gives you a good overview\n",
    "df[[\"views\", \"likes\", \"dislikes\", \"comment_count\", \"trending_days_difference\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0067e",
   "metadata": {},
   "source": [
    "Short explanation of the reported measures:\n",
    "- count: Indication of how many values are present in the columns (NaNs/missing values are not counted).\n",
    "- mean: average value of the data\n",
    "- std: standard deviation of the data\n",
    "- min: the smallest value in the data set\n",
    "- 25%: 25 % of the data are below this value\n",
    "- 50%: 50% of the data are below this value. This value is called the median.\n",
    "- 75%: 75% of the data are below this value\n",
    "- max: the largest expression in the data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6db44e",
   "metadata": {},
   "source": [
    "### Task\n",
    "#### What can you take away from this table?\n",
    "\n",
    "Please take some time to consider if the values make sense and make notes where things meet your expectations or what seems out of place.  \n",
    "\n",
    "1.  \n",
    "2.  \n",
    "3.  \n",
    "...  \n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12ff43",
   "metadata": {},
   "source": [
    "**From the table above we note that**\n",
    "- a trending video has on average 603.455 views, 21.875 likes, 1.397 dislikes and 2.785 comments\n",
    "- on average the time between the video is published and the video is trending is 1,85 days\n",
    "- the median value for the number of views is 119.277 which means that half of the trending videos have views that are less than that number, and the other half have views larger than that number. The same is true for the median of likes, dislikes, comment_count and trending_days_difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a80e5a",
   "metadata": {},
   "source": [
    "**Outliers**  \n",
    "We see in our descriptive statistics, that the minimum and maximum values in our numerical columns are far apart from each other. Let's have a look at these \"extreme\" values by looking at boxplots.  \n",
    "*Note:* The following code creates several subplots, meaning that all our numerical variables are plotted next to each other. This can be done by specifying the axes you want to plot each variable on (ax[0][0] means: first row, first column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504bec8",
   "metadata": {},
   "source": [
    "**Important**: In the following you will see a couple of extensive code block for generating plots. Please do not try to follow the code but rather on the output (the plots) which is generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7661c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(20,10)) # create subplots on 2 rows and 3 columns\n",
    "plt.suptitle('Distribution of numeric columns', fontsize=20)\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "ax[0][0].boxplot(x = df['views']) # creates boxplot for number of views\n",
    "ax[0][0].set_xticklabels(labels=[\"Views\"]) # sets the label for the ticks on the x-axis\n",
    "ax[0][0].set_ylim(0,2000000) # limits the y-axis values from 0 to 2000000 \n",
    "ax[0][0].set_title(\"Distribution of views count\", fontsize = 15); # sets title for subplot\n",
    "\n",
    "ax[0][1].boxplot(x = df['likes'])\n",
    "ax[0][1].set_xticklabels(labels=[\"Likes\"])\n",
    "ax[0][1].set_ylim(0,50000)\n",
    "ax[0][1].set_title(\"Distribution of likes count\", fontsize = 15);\n",
    "\n",
    "ax[0][2].boxplot(x = df['dislikes'])\n",
    "ax[0][2].set_xticklabels(labels=[\"Dislikes\"])\n",
    "ax[0][2].set_ylim(0,6000)\n",
    "ax[0][2].set_title(\"Distribution of dislikes count\", fontsize = 15);\n",
    "\n",
    "ax[1][0].boxplot(x = df['comment_count'])\n",
    "ax[1][0].set_xticklabels(labels=[\"Comment count\"])\n",
    "ax[1][0].set_ylim(0,20000)\n",
    "ax[1][0].set_title(\"Distribution of comment count\", fontsize = 15);\n",
    "                              \n",
    "ax[1][1].boxplot(x = df['trending_days_difference'])\n",
    "ax[1][1].set_xticklabels(labels=[\"Trending days difference\"])\n",
    "ax[1][1].set_ylim(-1,10)\n",
    "ax[1][1].set_title(\"Distribution of difference in trending time\", fontsize = 15);\n",
    "\n",
    "fig.delaxes(ax[1][2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a8adb",
   "metadata": {},
   "source": [
    "We can see that most of the values lie in the lower part of our distribution (50% of our data lies below the red line which represents the median).  \n",
    "But there are also a couple of videos with a very high number of views, likes, dislikes and comments. Since we can expect some videos to become much more popular than others, these extreme values can be expected and should not be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555d8f2",
   "metadata": {},
   "source": [
    "### Task\n",
    "#### How would you describe these distribution? \n",
    "Please take some time to think about this question and take some notes here.  \n",
    "\n",
    "1.  \n",
    "2.  \n",
    "3.  \n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a79062",
   "metadata": {},
   "source": [
    "Let's look at the distribution with the help of histograms. This might take some time to run, please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500794b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(20,10)) # create subplots on 2 rows and 3 columns\n",
    "plt.suptitle('Distribution of numeric columns', fontsize=20)\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "ax[0][0].hist(x=df['views'], bins=10000)  # creates histogram for number of views\n",
    "ax[0][0].set_ylabel(\"No of videos\", fontsize = 10) # sets the label y-axis\n",
    "ax[0][0].set_xlim(0,1000000) # limits the x-axis values from 0 to 1000000 \n",
    "ax[0][0].set_title(\"Distribution of views count\", fontsize = 15);  # sets title for subplot\n",
    "\n",
    "ax[0][1].hist(x= df['likes'], bins=5000)\n",
    "ax[0][1].set_ylabel(\"No of videos\", fontsize = 10)\n",
    "ax[0][1].set_xlim(0,50000)\n",
    "ax[0][1].set_title(\"Distribution of likes count\", fontsize = 15);\n",
    "\n",
    "ax[0][2].hist(x=df['dislikes'], bins=5000)\n",
    "ax[0][2].set_ylabel(\"No of videos\", fontsize = 10)\n",
    "ax[0][2].set_xlim(0,6000)\n",
    "ax[0][2].set_title(\"Distribution of dislikes count\", fontsize = 15);\n",
    "\n",
    "ax[1][0].hist(x=df['comment_count'], bins=1000)\n",
    "ax[1][0].set_ylabel(\"No of videos\", fontsize = 10)\n",
    "ax[1][0].set_xlim(0,20000)\n",
    "ax[1][0].set_title(\"Distribution of comment count\", fontsize = 15);\n",
    "                              \n",
    "ax[1][1].hist(x=df['trending_days_difference'], bins=1000)\n",
    "ax[1][1].set_ylabel(\"No of videos\", fontsize = 10)\n",
    "ax[1][1].set_xlim(0,10)\n",
    "ax[1][1].set_title(\"Distribution of difference in trending time\", fontsize = 15);\n",
    "\n",
    "fig.delaxes(ax[1][2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8515f99",
   "metadata": {},
   "source": [
    "We see, that we have right skewed distributions, meaning that the mean, median, and mode are all different from each other. In this case, the mode is the highest point of the histogram, whereas the median and mean fall to the right of it (or, visually, the right of the peak). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3384ce2",
   "metadata": {},
   "source": [
    "**We have made it through the data cleaning process!**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9381ba7",
   "metadata": {},
   "source": [
    "# 5 Answer questions\n",
    "## Addressing the Business Case: Hypotheses Driven Approach\n",
    "\n",
    "We have a dataset that we understand and we know it contains valid (or at least plausible) data. We can go ahead and try to create some knowledge and insights to share with our colleagues. We do this by stating our initial ideas as hypotheses that we will then test with the data to see if we they can be confirmed or rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14c495",
   "metadata": {},
   "source": [
    "The first step after browsing through our data confirming it is clean and logical, we now want to build some hypotheses in relation to our business case and the questions asked in the beginning.  \n",
    "The next task will be to look at the data columns in order to develop some hypotheses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216394d",
   "metadata": {},
   "source": [
    "### Task \n",
    "Write down your own hypotheses about what we could learn from the dataset.   \n",
    "These hypotheses should be a statement about some insights or relationship you might find in the data and which are related to your questions you want to answer.  \n",
    "They can be written as a positive statement that you can prove or disprove.\n",
    "\n",
    "1.  \n",
    "2.  \n",
    "3.  \n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c188e77",
   "metadata": {},
   "source": [
    "#### Our Hypotheses\n",
    "Since we all need to follow the same hypotheses in this code-along, we use the following hypotheses for exploration during the next steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e920b",
   "metadata": {},
   "source": [
    "1. Video-Categories differ in amount of trending videos, views, likes and dislikes\n",
    "2. For certain categories it takes longer to become a trending video after publication than for other categories\n",
    "3. Some YouTube channels are more successful than others\n",
    "4. The amount of video publications differ per day and hour\n",
    "5. Correlations exist between views, likes, dislikes and comments\n",
    "6. The length of time-interval between the date a video gets published and a video becomes trending also is correlated to number of views, likes, dislikes and comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52506d",
   "metadata": {},
   "source": [
    "In the following we will use the plotting library seaborn (abbreviated by sns). Seaborn is built on top of Matplotlib and extends its options.   \n",
    "Again, do not try to follow the code in detail but rather focus on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23921bf2",
   "metadata": {},
   "source": [
    "**1. Video-Categories differ in amount of trending videos, views, likes and dislikes**  \n",
    "**2. For certain categories it takes longer to become a trending video after publication than for other categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e10b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of videos per category\n",
    "plt.figure(figsize=(15,8)) # specify figure size\n",
    "f1 = sns.countplot(x=df['category_name']) # create countplot\n",
    "f1.tick_params(axis='x', rotation=90) # get x-ticks and rotate them\n",
    "f1.set(xlabel=None) # set no label for x-axis \n",
    "f1.set_ylabel(\"No of videos\", fontsize = 10); # set label for y-axis\n",
    "f1.set_title('Number of videos per category', fontsize=20); # set title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c6428",
   "metadata": {},
   "source": [
    "We can see, that most of the trending videos belong to the entertainment category. Music is more in the midfield when it comes to the amount of trending videos. The Categories will be represented by the same color in each of the following charts so note the categories we are primarily interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e150b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot views, likes, dislikes and comments per category\n",
    "fig, ax = plt.subplots(2,3, figsize=(20,15)) # create subplots on 2 rows and 2 columns\n",
    "plt.suptitle('Likes, dislikes, views and comments per category', fontsize=20) \n",
    "fig.tight_layout()   # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .6, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "f1 = sns.barplot(x=df[\"category_name\"], y = df['views'], ax=ax[0,0], ci = None) # creates barchart for number of views\n",
    "f1.tick_params(axis='x', labelrotation=90) # sets the label y-axis\n",
    "f1.set(xlabel=None) # sets the x-axis label\n",
    "f1.set_ylabel(\"Number of views\", fontsize = 10) # limits the x-axis values from 0 to 1000000\n",
    "f1.set_title(\"Views per category\", fontsize = 15);  # sets title for subplot\n",
    "\n",
    "f2= sns.barplot(x=df[\"category_name\"], y = df['likes'], ax=ax[0,1], ci = None)\n",
    "f2.tick_params(axis='x', labelrotation=90)\n",
    "f2.set(xlabel=None)\n",
    "f2.set_ylabel(\"Number of likes\", fontsize = 10)\n",
    "f2.set_title(\"Likes per category\", fontsize = 15);\n",
    "\n",
    "f3 = sns.barplot(x=df[\"category_name\"], y = df['dislikes'], ax=ax[0,2], ci = None)\n",
    "f3.tick_params(axis='x', labelrotation=90)\n",
    "f3.set(xlabel=None)\n",
    "f3.set_ylabel(\"Number of dislikes\", fontsize = 10)\n",
    "f3.set_title(\"Dislikes per category\", fontsize = 15);\n",
    "\n",
    "f4 = sns.barplot(x=df[\"category_name\"], y = df['comment_count'], ax=ax[1,0], ci = None)\n",
    "f4.tick_params(axis='x', labelrotation=90)\n",
    "f4.set(xlabel=None)\n",
    "f4.set_ylabel(\"Number of comments\", fontsize = 10)\n",
    "f4.set_title(\"Comments per category\", fontsize = 15);\n",
    "\n",
    "f5 = sns.barplot(x=df[\"category_name\"], y = df['trending_days_difference'], ax=ax[1,1], ci = None)\n",
    "f5.tick_params(axis='x', labelrotation=90)\n",
    "f5.set(xlabel=None)\n",
    "f5.set_ylabel(\"Time period in days\", fontsize = 10)\n",
    "f5.set_title(\"Time period for trending per category\", fontsize = 15);\n",
    "\n",
    "fig.delaxes(ax[1][2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1abd3",
   "metadata": {},
   "source": [
    "Wow, music seems to be a promising category -  The videos belonging to this category have the most views, the most likes and the second most comments.  \n",
    "It is surprising though that the category with the most trending videos (Entertainment) does not have the highest number of likes, views and comments.  \n",
    "\n",
    "The time period for music videos to get trending is in comparison quite high - we should tell our agency to stay patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65829d80",
   "metadata": {},
   "source": [
    "**3.Some YouTube channels are more successful than others**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efffc9",
   "metadata": {},
   "source": [
    "In order to test this hypothesis, we will have a look the YouTube channels which have published the most trending videos in the music category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top5 channels across all categories\n",
    "df['channel_title'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1925efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top5 channels for category music\n",
    "df.query(\"category_name == 'Music'\")['channel_title'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc8717",
   "metadata": {},
   "source": [
    "385idéal seems to publish most trending videos. We should do some research on this channel and recommend it to our colleagues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9d3cb",
   "metadata": {},
   "source": [
    "**4. The amount of video publications differ per day and hour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(20,10))\n",
    "plt.suptitle('Video publication time', fontsize=20)\n",
    "fig.tight_layout(h_pad=8) \n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9)\n",
    "\n",
    "f1 = sns.countplot(x=df['publish_weekday'], ax=ax[0])\n",
    "f1.set_ylabel(\"No of published videos\", fontsize = 10)\n",
    "f1.set_xlabel(\"Weekday of publication\", fontsize = 10)\n",
    "f1.set_xticks([0,1,2,3,4,5,6])\n",
    "f1.set_xticklabels(labels=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "f1.set_title(\"Number of published videos per weekday\", fontsize = 15);\n",
    "\n",
    "f2 = sns.countplot(x=df['publish_hour'], ax=ax[1])\n",
    "f2.set_ylabel(\"No of published videos\", fontsize = 10)\n",
    "f2.set_xlabel(\"Hour of publication\", fontsize = 10)\n",
    "f2.set_title(\"Number of published videos per hour\", fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775836b6",
   "metadata": {},
   "source": [
    "On fridays most trending videos got published - looking at the exact time of the day, 5pm is the time, when most trending videos got published.  \n",
    "Let's do the same analysis only for the music category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music = df.query(\"category_name == 'Music'\")\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(20,10))\n",
    "plt.suptitle('Video publication time for Music videos', fontsize=20)\n",
    "fig.tight_layout(h_pad=8) \n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9)\n",
    "\n",
    "f1 = sns.countplot(x=df_music['publish_weekday'], ax=ax[0])\n",
    "f1.set_ylabel(\"No of published videos\", fontsize = 10)\n",
    "f1.set_xlabel(\"Weekday of publication\", fontsize = 10)\n",
    "f1.set_xticks([0,1,2,3,4,5,6])\n",
    "f1.set_xticklabels(labels=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "f1.set_title(\"Number of published videos per weekday\", fontsize = 15);\n",
    "\n",
    "f2 = sns.countplot(x=df_music['publish_hour'], ax=ax[1])\n",
    "f2.set_ylabel(\"No of published videos\", fontsize = 10)\n",
    "f2.set_xlabel(\"Hour of publication\", fontsize = 10)\n",
    "f2.set_title(\"Number of published videos per hour\", fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e07fc9",
   "metadata": {},
   "source": [
    "Friday seems to be THE day to publish the music videos of our stars! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e3c86",
   "metadata": {},
   "source": [
    "## Check for correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08e2f0",
   "metadata": {},
   "source": [
    "**5. Correlations exist between views, likes, dislikes and comments**  \n",
    "**6. The the length of time-interval between the date a video gets published and a video becomes trending also is correlated to number of views, likes, dislikes and comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix between these variables\n",
    "corr_columns=[\"views\", \"likes\", \"dislikes\", \"comment_count\", \"trending_days_difference\"]\n",
    "corr_mtrx=df[corr_columns].corr()\n",
    "corr_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b387cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the heatmap \n",
    "plt.figure(figsize = (14,12))\n",
    "ax = sns.heatmap(corr_mtrx, linewidths=.5, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1348efc",
   "metadata": {},
   "source": [
    "So there are notable positive relationships between\n",
    "- Views and: Likes and Comments \n",
    "- Likes and: Comments\n",
    "- Dislikes and Comments\n",
    "\n",
    "There are no relationships between these variables and the time period between publish date and trending date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee307e1",
   "metadata": {},
   "source": [
    "# 6 Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97744a19",
   "metadata": {},
   "source": [
    "We have managed to derive results in order to answer our questions.  \n",
    "However, it might be necessary to look deeper before delivering results and making suggestions to the agency.\n",
    "For example, looking for differences between Music videos.    \n",
    "Or evaluating a channel for publication not only based on number of music videos published, but also number of interactions with music videos.  \n",
    "**Task**: Think about further steps you should go through for validating your results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dcd8f9",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "1. Summarize the major issues and actions that needed to be addressed in cleaning and augmenting part. Could the decisions we took about cleaning affect the end understanding of the business case?   \n",
    "2. Summarize the findings of our analysis here. What will you tell your colleagues from the agency?   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71b166",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e4771abb73651cc71498e03f3559c7e0f15f38d5124065b3832974a7bbffea7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
